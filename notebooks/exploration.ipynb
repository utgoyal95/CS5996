{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2430225-5d7c-4d86-b6b6-19aac07b83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "686fb4eb-93a0-4f69-9fbe-b61f3e630881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dcgan_reproduction/train.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.utils.data import DataLoader\n",
    "from models import Generator, Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dda2f1e7-9974-41a5-83ea-c5773e338721",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = \"./data\"\n",
    "output_dir = \"./results/MINST/\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "image_size = 64\n",
    "batch_size = 128\n",
    "nz = 100             # Latent vector size\n",
    "gf_dim = 64          # Generator feature maps\n",
    "df_dim = 64          # Discriminator feature maps\n",
    "nc = 1               # Number of channels (1 for grayscale MNIST)\n",
    "epochs = 25\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7fff52b-94e2-4ce5-8715-15c29ab48d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dset.MNIST(root=data_root, download=True,\n",
    "                     transform=transforms.Compose([\n",
    "                         transforms.Resize(image_size),\n",
    "                         transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5,), (0.5,))]))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28a4e4b7-47e5-4a15-8bfb-6e4dc6ea5fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "netG = Generator.Generator(nz, gf_dim, nc).to(device)\n",
    "netD = Discriminator.Discriminator(nc, df_dim).to(device)\n",
    "\n",
    "netG.apply(lambda m: nn.init.normal_(m.weight.data, 0.0, 0.02) if isinstance(m, (nn.ConvTranspose2d, nn.BatchNorm2d)) else None)\n",
    "netD.apply(lambda m: nn.init.normal_(m.weight.data, 0.0, 0.02) if isinstance(m, (nn.Conv2d, nn.BatchNorm2d)) else None)\n",
    "\n",
    "# ─── LOSS AND OPTIMIZER ───────────────────────────────────────────────────────\n",
    "criterion = nn.BCELoss()\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38085249-fc01-415a-9d61-2eb80b3bb4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Loop...\n",
      "[0/25][0/469] Loss_D: 1.3910 Loss_G: 0.7076\n",
      "[0/25][100/469] Loss_D: 0.0255 Loss_G: 4.2928\n",
      "[0/25][200/469] Loss_D: 0.0069 Loss_G: 5.5793\n",
      "[0/25][300/469] Loss_D: 0.0032 Loss_G: 6.3991\n",
      "[0/25][400/469] Loss_D: 1.1411 Loss_G: 1.6604\n",
      "[1/25][0/469] Loss_D: 2.4441 Loss_G: 3.3817\n",
      "[1/25][100/469] Loss_D: 0.6220 Loss_G: 1.4447\n",
      "[1/25][200/469] Loss_D: 0.9766 Loss_G: 3.2113\n",
      "[1/25][300/469] Loss_D: 0.6480 Loss_G: 2.2867\n",
      "[1/25][400/469] Loss_D: 0.7916 Loss_G: 1.0948\n",
      "[2/25][0/469] Loss_D: 0.6578 Loss_G: 1.5846\n",
      "[2/25][100/469] Loss_D: 0.8899 Loss_G: 1.3300\n",
      "[2/25][200/469] Loss_D: 0.7912 Loss_G: 1.3941\n",
      "[2/25][300/469] Loss_D: 0.7101 Loss_G: 1.1326\n",
      "[2/25][400/469] Loss_D: 0.8385 Loss_G: 0.7545\n",
      "[3/25][0/469] Loss_D: 0.7196 Loss_G: 2.4997\n",
      "[3/25][100/469] Loss_D: 0.8434 Loss_G: 1.4746\n",
      "[3/25][200/469] Loss_D: 0.7805 Loss_G: 3.7110\n",
      "[3/25][300/469] Loss_D: 0.5411 Loss_G: 1.7637\n",
      "[3/25][400/469] Loss_D: 0.9984 Loss_G: 0.4302\n",
      "[4/25][0/469] Loss_D: 0.7207 Loss_G: 1.6145\n",
      "[4/25][100/469] Loss_D: 1.0502 Loss_G: 1.0010\n",
      "[4/25][200/469] Loss_D: 0.7284 Loss_G: 1.2421\n",
      "[4/25][300/469] Loss_D: 0.4616 Loss_G: 2.0514\n",
      "[4/25][400/469] Loss_D: 0.5558 Loss_G: 1.4276\n",
      "[5/25][0/469] Loss_D: 0.5592 Loss_G: 3.3674\n",
      "[5/25][100/469] Loss_D: 0.3684 Loss_G: 2.1165\n",
      "[5/25][200/469] Loss_D: 0.5932 Loss_G: 2.7857\n",
      "[5/25][300/469] Loss_D: 0.6916 Loss_G: 1.9416\n",
      "[5/25][400/469] Loss_D: 0.9116 Loss_G: 1.2391\n",
      "[6/25][0/469] Loss_D: 0.5925 Loss_G: 2.2470\n",
      "[6/25][100/469] Loss_D: 0.6070 Loss_G: 4.0046\n",
      "[6/25][200/469] Loss_D: 0.4382 Loss_G: 3.4185\n",
      "[6/25][300/469] Loss_D: 0.6474 Loss_G: 2.1206\n",
      "[6/25][400/469] Loss_D: 0.7206 Loss_G: 1.9458\n",
      "[7/25][0/469] Loss_D: 0.7890 Loss_G: 4.1627\n",
      "[7/25][100/469] Loss_D: 0.7772 Loss_G: 1.2183\n",
      "[7/25][200/469] Loss_D: 0.4464 Loss_G: 2.1200\n",
      "[7/25][300/469] Loss_D: 0.7445 Loss_G: 3.6702\n",
      "[7/25][400/469] Loss_D: 0.7972 Loss_G: 0.8444\n",
      "[8/25][0/469] Loss_D: 0.4238 Loss_G: 2.4134\n",
      "[8/25][100/469] Loss_D: 1.0325 Loss_G: 1.5252\n",
      "[8/25][200/469] Loss_D: 1.5678 Loss_G: 0.9956\n",
      "[8/25][300/469] Loss_D: 0.2923 Loss_G: 2.5702\n",
      "[8/25][400/469] Loss_D: 0.4216 Loss_G: 4.4946\n",
      "[9/25][0/469] Loss_D: 0.5255 Loss_G: 2.5199\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(epochs):\n",
    "    for i, (real_images, _) in enumerate(dataloader):\n",
    "        # Update Discriminator\n",
    "        netD.zero_grad()\n",
    "        real_images = real_images.to(device)\n",
    "        b_size = real_images.size(0)\n",
    "        labels_real = torch.full((b_size,), 1., dtype=torch.float, device=device)\n",
    "        output = netD(real_images).view(-1)\n",
    "        errD_real = criterion(output, labels_real)\n",
    "\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        fake_images = netG(noise)\n",
    "        labels_fake = torch.full((b_size,), 0., dtype=torch.float, device=device)\n",
    "        output = netD(fake_images.detach()).view(-1)\n",
    "        errD_fake = criterion(output, labels_fake)\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        errD.backward()\n",
    "        optimizerD.step()\n",
    "\n",
    "        # Update Generator\n",
    "        netG.zero_grad()\n",
    "        labels_gen = torch.full((b_size,), 1., dtype=torch.float, device=device)\n",
    "        output = netD(fake_images).view(-1)\n",
    "        errG = criterion(output, labels_gen)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[{epoch}/{epochs}][{i}/{len(dataloader)}] Loss_D: {errD.item():.4f} Loss_G: {errG.item():.4f}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        fake = netG(fixed_noise).detach().cpu()\n",
    "        vutils.save_image(fake, f\"{output_dir}/fake_samples_epoch_{epoch:03d}.png\", normalize=True)\n",
    "\n",
    "print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5cc54-8b10-4a20-8744-03e429c42eef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
